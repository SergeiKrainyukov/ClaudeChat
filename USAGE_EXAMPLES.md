# Примеры использования сравнения моделей

## Базовое использование

### Пример 1: Сравнение легких моделей

**Модели:**
- gpt2
- distilgpt2

**Запрос:**
```
Write a short story about a robot learning to paint.
```

**Ожидаемый результат:**
- gpt2 обычно генерирует более подробный текст
- distilgpt2 быстрее, но может быть менее креативным
- Время ответа: gpt2 (~2-3 сек), distilgpt2 (~1-2 сек)

### Пример 2: Диалоговые модели

**Модели (изменить в коде):**
- microsoft/DialoGPT-medium
- facebook/blenderbot-400M-distill

**Запрос:**
```
Hello! How are you today?
```

**Ожидаемый результат:**
- Обе модели оптимизированы для диалога
- Сравнение естественности ответов

## Продвинутое использование

### Программное изменение моделей

В `ModelComparisonViewModel.kt`:

```kotlin
// Изменить модели по умолчанию
private var model1Id = "EleutherAI/gpt-neo-125M"
private var model2Id = "facebook/opt-125m"
```

### Настройка параметров генерации

В `HuggingFaceRepository.kt`, метод `generateText`:

```kotlin
val request = HuggingFaceRequest(
    inputs = prompt,
    parameters = HuggingFaceParameters(
        max_new_tokens = 256,      // Количество токенов
        temperature = 0.7,         // Креативность (0.0-1.0)
        topP = 0.9,               // Nucleus sampling
        doSample = true            // Использовать семплирование
    )
)
```

**Параметры:**
- `max_new_tokens` (50-1024): больше = длиннее ответ
- `temperature` (0.0-1.0): выше = креативнее, ниже = предсказуемее
- `topP` (0.0-1.0): nucleus sampling, контролирует разнообразие
- `doSample`: включить/выключить семплирование

## Сценарии тестирования

### 1. Сравнение скорости

**Цель:** Узнать, какая модель быстрее

**Модели:**
- gpt2 (большая)
- distilgpt2 (маленькая)

**Запрос:** Короткий промпт
```
Count from 1 to 10
```

### 2. Сравнение качества

**Цель:** Оценить качество текста

**Модели:**
- gpt2
- EleutherAI/gpt-neo-125M

**Запрос:** Творческая задача
```
Write a poem about artificial intelligence
```

### 3. Многоязычность

**Модели:**
- gpt2 (английский)
- Модель с поддержкой русского

**Запрос на русском:**
```
Расскажи короткую историю про космос
```

## Рекомендуемые комбинации

### Для быстрых экспериментов
```
Модель 1: gpt2
Модель 2: distilgpt2
```

### Для сравнения архитектур
```
Модель 1: gpt2 (GPT архитектура)
Модель 2: facebook/opt-125m (OPT архитектура)
```

### Для диалоговых задач
```
Модель 1: microsoft/DialoGPT-medium
Модель 2: facebook/blenderbot-400M-distill
```

## Интерпретация результатов

### Время ответа

- **< 2 сек:** Отлично
- **2-5 сек:** Хорошо
- **5-20 сек:** Модель загружается (первый запрос)
- **> 20 сек:** Возможны проблемы с сервером

### Качество текста

Оценивайте по критериям:
1. **Связность:** Логичен ли текст?
2. **Релевантность:** Ответ по теме?
3. **Грамматика:** Есть ли ошибки?
4. **Креативность:** Насколько интересен ответ?

### Длина ответа

- Короткие ответы: модель может быть ограничена или слишком консервативна
- Длинные ответы: модель может быть более креативной, но иногда повторяется

## Типичные проблемы

### Модель возвращает только часть запроса

**Проблема:** Ответ начинается с вашего запроса

**Решение:** Уже реализовано в `HuggingFaceRepository.kt`:
```kotlin
val cleanText = if (generatedText.startsWith(prompt)) {
    generatedText.substring(prompt.length).trim()
} else {
    generatedText.trim()
}
```

### Модель генерирует повторяющийся текст

**Решение:** Уменьшите `temperature` в параметрах:
```kotlin
temperature = 0.5  // вместо 0.7
```

### Модель отвечает на английском на русский запрос

**Проблема:** Модель обучена только на английском

**Решение:** Используйте многоязычную модель, например:
- `facebook/mbart-large-50` (но она может быть медленной)
- Попробуйте запрос на английском

## Метрики для оценки

При сравнении моделей учитывайте:

1. **Скорость (мс)** - из результатов
2. **Длина ответа (символы)** - из результатов
3. **Качество (субъективно)** - оценка 1-5
4. **Релевантность (субъективно)** - оценка 1-5
5. **Использование памяти** - указано в документации модели

Пример таблицы для ваших записей:

| Модель | Скорость | Длина | Качество | Релевантность | Примечания |
|--------|----------|-------|----------|---------------|------------|
| gpt2 | 2500ms | 450 | 4/5 | 5/5 | Хороший баланс |
| distilgpt2 | 1800ms | 380 | 3/5 | 4/5 | Быстрее, но проще |

## Дальнейшие эксперименты

1. **A/B тестирование:** Сохраните результаты в базу данных
2. **Автоматическая оценка:** Используйте метрики (BLEU, ROUGE)
3. **Пользовательское голосование:** Добавьте кнопки "лучше/хуже"
4. **История сравнений:** Сохраняйте предыдущие результаты

## Ссылки

- [Hugging Face Models](https://huggingface.co/models?pipeline_tag=text-generation)
- [Text Generation Parameters](https://huggingface.co/docs/api-inference/detailed_parameters#text-generation-task)
- [Model Cards](https://huggingface.co/docs/hub/model-cards) - информация о каждой модели